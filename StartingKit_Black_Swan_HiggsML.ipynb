{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34RSjxqveykf"
      },
      "source": [
        "***\n",
        "# Starting Kit - Black Swan HiggsML Course\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2BwG8lTMeykg"
      },
      "outputs": [],
      "source": [
        "COLAB = \"google.colab\" in str(get_ipython())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W-_jTLvReykg",
        "outputId": "82d02bda-6111-4149-d013-c82ab95d16c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Higgs_collaborations' already exists and is not an empty directory.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "/content/Higgs_collaborations\n"
          ]
        }
      ],
      "source": [
        "if COLAB:\n",
        "    ! git clone --depth 1 https://github.com/AboodJamal/Higgs_collaborations.git\n",
        "\n",
        "    ! git status\n",
        "    %cd Higgs_collaborations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h3BFItxVeykh"
      },
      "outputs": [],
      "source": [
        "# HiggsML utility package should not be modified\n",
        "# %pip install HiggsML\n",
        "# %pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QJEQntQceykh"
      },
      "outputs": [],
      "source": [
        "# !pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xm41WKXBeykh",
        "outputId": "be42775a-b382-493b-b235-063824d7fad4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "id": "RuWO9YJ1giVr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxVwS281eyki"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RThRKucEeyki"
      },
      "outputs": [],
      "source": [
        "from sys import path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "from numpy.random import RandomState\n",
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "import mlflow\n",
        "import mlflow.keras\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7lDuPTmeyki"
      },
      "source": [
        "### Directories"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mplhep"
      ],
      "metadata": {
        "id": "Y12xH8I_noXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install HiggsML"
      ],
      "metadata": {
        "id": "vwVc-aTfnLH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIcBNuIxeyki"
      },
      "outputs": [],
      "source": [
        "!pip install iminuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z4hBrpDeyki"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Get root and submission directories\n",
        "root_dir = os.getcwd()\n",
        "print(\"Root directory is\", root_dir)\n",
        "\n",
        "submission_dir = os.path.join(root_dir, \"sample_code_submission\")\n",
        "\n",
        "# The directory where results will be written\n",
        "output_dir = os.path.join(root_dir, \"sample_result_submission\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Add submission directory to sys.path\n",
        "sys.path.append(submission_dir)\n",
        "\n",
        "# Now import the model\n",
        "from model import Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtVkIFWfeyki"
      },
      "source": [
        "## Import Submission Model\n",
        "We import a class named `Model` from the submission file (`model.py`). This `Model` class has the following methods:\n",
        "- `init`: receives train set and systematics class as input\n",
        "- `fit`: can be used for training\n",
        "- `predict`: receives one test set and outputs a dictionary with the following keys\n",
        "    - `mu_hat` : predicted mu $\\hat{\\mu}$\n",
        "    - `delta_mu_hat`: $\\Delta{\\hat{\\mu}}$ bound for $\\mu$\n",
        "    - `p16`: 16th percentile\n",
        "    - `p84`: 84th percentile\n",
        "\n",
        "In this example code, the `Model` class implements a basic model with 2 different model trained to predict the class label.\n",
        "\n",
        "* 1 XGBoost BDT ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/boosted_decision_tree.py) )\n",
        "* 2 Tebsorflow NN  ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/neural_network.py) )\n",
        "\n",
        "The feature engineering is in where you can include derived quantities and decide which feature should be needed. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/feature_engineering.py) )\n",
        "\n",
        "the statistical analysis part is where yoiu write the mu finding calculation using the output of the classifier. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/statistical_analysis.py) )\n",
        "\n",
        "If running in Collab, click the folder icon in the left sidebar to open the file browser.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ednRYfSeykj"
      },
      "source": [
        "## Data\n",
        "### Available data sets\n",
        "1. blackSwan_data\n",
        "2. sample_data\n",
        "3. neurips2024_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka-aoNQbeykj"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naWB8Ri8eykj"
      },
      "outputs": [],
      "source": [
        "from HiggsML.datasets import download_dataset\n",
        "\n",
        "data = download_dataset(\n",
        "    \"blackSwan_data\"\n",
        ")  # change to \"blackSwan_data\" for the actual data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksnn5mIKeykj"
      },
      "source": [
        "### ⚠️ Note:\n",
        "The data used here is a small subset of the full data is for demonstration only to get a view of what the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8pYJyN7eykj"
      },
      "outputs": [],
      "source": [
        "# load train set\n",
        "data.load_train_set()\n",
        "data_set = data.get_train_set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kNoHBl-eykj"
      },
      "source": [
        "***\n",
        "## Visualize the Data Set\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1CQM9oseykj"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "target = data_set[\"labels\"]\n",
        "weights = data_set[\"weights\"]\n",
        "detailed_label = data_set[\"detailed_labels\"]\n",
        "keys = np.unique(detailed_label)\n",
        "\n",
        "\n",
        "weight_keys = {}\n",
        "average_weights = {}\n",
        "for key in keys:\n",
        "    weight_keys[key] = weights[detailed_label == key]\n",
        "\n",
        "table_data = []\n",
        "for key in keys:\n",
        "    table_data.append(\n",
        "        [\n",
        "            key,\n",
        "            np.sum(weight_keys[key]),\n",
        "            len(weight_keys[key]),\n",
        "            np.mean(weight_keys[key]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "table_data.append(\n",
        "    [\n",
        "        \"Total Signal\",\n",
        "        np.sum(weights[target == 1]),\n",
        "        len(weights[target == 1]),\n",
        "        np.mean(weights[target == 1]),\n",
        "    ]\n",
        ")\n",
        "table_data.append(\n",
        "    [\n",
        "        \"Total Background\",\n",
        "        np.sum(weights[target == 0]),\n",
        "        len(weights[target == 0]),\n",
        "        np.mean(weights[target == 0]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"[*] --- Detailed Label Summary\")\n",
        "print(\n",
        "    tabulate(\n",
        "        table_data,\n",
        "        headers=[\n",
        "            \"Detailed Label\",\n",
        "            \"Total Weight\",\n",
        "            \"Number of events\",\n",
        "            \"Average Weight\",\n",
        "        ],\n",
        "        tablefmt=\"grid\",\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pm-Rq7jeykj"
      },
      "outputs": [],
      "source": [
        "print(\"\\n[*] --- Examples of all features\\n\")\n",
        "display(data_set.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wug9C1uQeykk"
      },
      "outputs": [],
      "source": [
        "print(\"\\n[*] --- Description of all features\\n\")\n",
        "display(data_set.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsTsTTOSeykk"
      },
      "outputs": [],
      "source": [
        "print(\"\\n[*] --- Labels vs. Detailed Labels\\n\")\n",
        "display(data_set[[\"labels\", \"detailed_labels\"]].head(70))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqJIPuFUeykk"
      },
      "outputs": [],
      "source": [
        "# !pip install mplhep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GJMSnJreykk"
      },
      "outputs": [],
      "source": [
        "from utils import histogram_dataset\n",
        "\n",
        "# this function is defined in utils.py in the sample_code_submission directory. feel free to modify it as needed\n",
        "\n",
        "histogram_dataset(\n",
        "    data_set,\n",
        "    target,\n",
        "    weights,\n",
        "    columns=[\"PRI_lep_phi\", \"PRI_met\", \"DER_mass_vis\", \"DER_deltaeta_jet_jet\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAsc3SkXeykk"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme(rc={\"figure.figsize\": (10, 10)}, style=\"whitegrid\")\n",
        "\n",
        "caption = [\"Signal feature\", \"Background feature\"]\n",
        "\n",
        "for i in range(2):\n",
        "\n",
        "    dfplot = pd.DataFrame(\n",
        "        data_set,\n",
        "        columns=[\n",
        "            \"PRI_lep_phi\",\n",
        "            \"PRI_met\",\n",
        "            \"DER_pt_ratio_lep_had\",\n",
        "            \"DER_deltaeta_jet_jet\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    print(caption[i], \" correlation matrix\")\n",
        "    corrMatrix = dfplot[target == i].corr()\n",
        "    sns.heatmap(corrMatrix, annot=True)\n",
        "    plt.title(\"Correlation matrix of features\")\n",
        "    plt.show()\n",
        "\n",
        "del dfplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5CqY3vBeykk"
      },
      "outputs": [],
      "source": [
        "from HiggsML.visualization import stacked_histogram\n",
        "\n",
        "stacked_histogram(data_set, target, weights, detailed_label, \"PRI_jet_subleading_pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMk5BgFBeykk"
      },
      "outputs": [],
      "source": [
        "from HiggsML.visualization import pair_plots\n",
        "\n",
        "# Show data summary\n",
        "pair_plots(\n",
        "    data_set,\n",
        "    target,\n",
        "    sample_size=100,\n",
        "    columns=[\n",
        "        \"PRI_lep_phi\",\n",
        "        \"PRI_met\",\n",
        "        \"DER_lep_eta_centrality\",\n",
        "        \"DER_deltaeta_jet_jet\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1fkP_cMeykk"
      },
      "source": [
        "### Ingestion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AytlZVTeykk"
      },
      "source": [
        "Ingestion is part of your competition framework (from HiggsML.ingestion). Its job is to:\n",
        "\n",
        "| Responsibility                   | Explanation                                                |\n",
        "| -------------------------------- | ---------------------------------------------------------- |\n",
        "| Standardize model interface      | Calls `Model.__init__`, `fit`, `predict` with correct args |\n",
        "| Pass dataset correctly           | Gives your model access to `get_train_set()`               |\n",
        "| Enforce submission rules         | Checks naming, format, timing, and required outputs        |\n",
        "| Log outputs and monitor training | Might save logs, errors, or performance                    |\n",
        "| Run evaluation (sometimes)       | Possibly computes metrics like `mu_hat` or AUC             |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X34upsneeykk"
      },
      "outputs": [],
      "source": [
        "from HiggsML.ingestion import Ingestion\n",
        "\n",
        "ingestion = Ingestion(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gUugm5Geykl"
      },
      "outputs": [],
      "source": [
        "# initialize submission\n",
        "ingestion.init_submission(Model,\"NN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzIo9x2reykl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIFApLGxeykl"
      },
      "outputs": [],
      "source": [
        "# fit submission\n",
        "ingestion.fit_submission()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZdPW9y7eykl"
      },
      "outputs": [],
      "source": [
        "# load test set\n",
        "data.load_test_set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLcobE0qeykl"
      },
      "source": [
        "### Test Settings\n",
        "The Test setting sets the test conditions in ingestion.\n",
        "This includes what systematics you want and how many psuedo experiments you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_6sTC16eykl"
      },
      "outputs": [],
      "source": [
        "test_settings = {\n",
        "    \"systematics\": {  # Systematics to use\n",
        "        \"tes\": False,  # tau energy scale\n",
        "        \"jes\": False,  # jet energy scale\n",
        "        \"soft_met\": False,  # soft term in MET\n",
        "        \"ttbar_scale\": False,  # W boson scale factor\n",
        "        \"diboson_scale\": False,  # Diboson scale factor\n",
        "        \"bkg_scale\": False,  # Background scale factor\n",
        "    },\n",
        "    \"num_pseudo_experiments\": 20,  # Number of pseudo-experiments to run per set\n",
        "    \"num_of_sets\": 1,  # Number of sets of pseudo-experiments to run.\n",
        "}\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "random_state = np.random.RandomState(RANDOM_SEED)\n",
        "test_settings[\"ground_truth_mus\"] = (\n",
        "    random_state.uniform(0.1, 3, test_settings[\"num_of_sets\"])\n",
        ").tolist()\n",
        "\n",
        "random_settings_file = os.path.join(output_dir, \"test_settings.json\")\n",
        "with open(random_settings_file, \"w\") as f:\n",
        "    json.dump(test_settings, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBELfCZseykl"
      },
      "outputs": [],
      "source": [
        "# predict submission\n",
        "ingestion.predict_submission(test_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyVd5f_Oeykl"
      },
      "outputs": [],
      "source": [
        "ingestion.process_results_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5u-okDzeykl"
      },
      "outputs": [],
      "source": [
        "# save result\n",
        "ingestion.save_result(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wr3mBLNeykp"
      },
      "source": [
        "## Score\n",
        "1. Compute Scores\n",
        "2. Visualize Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDNz4ATkeykp"
      },
      "outputs": [],
      "source": [
        "from HiggsML.score import Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU3KeIhUeykp"
      },
      "outputs": [],
      "source": [
        "# Initialize Score\n",
        "score = Scoring()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxXjE7G2eykp"
      },
      "outputs": [],
      "source": [
        "print(output_dir)\n",
        "score.load_ingestion_results(prediction_dir=output_dir, score_dir=output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-uO78Xzeykp"
      },
      "outputs": [],
      "source": [
        "# !pip install pydot graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veygq13eeykp"
      },
      "outputs": [],
      "source": [
        "from utils import visualize_model_architecture\n",
        "from neural_network import NeuralNetwork\n",
        "from HiggsML.datasets import download_dataset\n",
        "\n",
        "# Load dataset\n",
        "data = download_dataset(\"blackSwan_data\")\n",
        "data.load_train_set()\n",
        "data_set = data.get_train_set()\n",
        "\n",
        "X_train = data_set.iloc[:, :-1]  # Features only\n",
        "\n",
        "model_instance = NeuralNetwork(X_train)\n",
        "visualize_model_architecture(model_instance.model, filename=\"nn_architecture.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8qjP4y7eykq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(\"Current notebook working directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47Sdtw_leykq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdqai4Wfeykq"
      },
      "outputs": [],
      "source": [
        "# Compute Score\n",
        "score.compute_scores(test_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rkLYHu6eykq"
      },
      "outputs": [],
      "source": [
        "from HiggsML.visualization import visualize_scatter\n",
        "\n",
        "# Visualize scatter plot of ground truth mu and predicted mu\n",
        "visualize_scatter(\n",
        "    ingestion_result_dict=ingestion.results_dict,\n",
        "    ground_truth_mus=test_settings[\"ground_truth_mus\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov4DEO2beykq"
      },
      "outputs": [],
      "source": [
        "!python -m HiggsML.score --prediction $output_dir --output $output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBO2Vffzeykq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}